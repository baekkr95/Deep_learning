{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        output = self.linear(X)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "model = LogisticRegression(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [[[0], [0], [0], [1]]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        output = self.linear(X)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "model = LogisticRegression(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:0/100000] Loss: 0.8141\n",
      "[Epoch:10000/100000] Loss: 0.5114\n",
      "[Epoch:20000/100000] Loss: 0.3913\n",
      "[Epoch:30000/100000] Loss: 0.3201\n",
      "[Epoch:40000/100000] Loss: 0.2725\n",
      "[Epoch:50000/100000] Loss: 0.2381\n",
      "[Epoch:60000/100000] Loss: 0.2117\n",
      "[Epoch:70000/100000] Loss: 0.1908\n",
      "[Epoch:80000/100000] Loss: 0.1736\n",
      "[Epoch:90000/100000] Loss: 0.1593\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100000\n",
    "total = 0\n",
    "correct = 0\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    prediction = model(x)\n",
    "    loss = criterion(prediction, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10000 == 0:\n",
    "        print(f'[Epoch:{epoch}/{epochs}] Loss: {round(loss.item(), 4)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [[[0], [1], [1], [1]]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        output = self.linear(X)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "model = LogisticRegression(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:0/100000] Loss: 0.5353\n",
      "[Epoch:10000/100000] Loss: 0.3204\n",
      "[Epoch:20000/100000] Loss: 0.2529\n",
      "[Epoch:30000/100000] Loss: 0.2078\n",
      "[Epoch:40000/100000] Loss: 0.1756\n",
      "[Epoch:50000/100000] Loss: 0.1515\n",
      "[Epoch:60000/100000] Loss: 0.133\n",
      "[Epoch:70000/100000] Loss: 0.1182\n",
      "[Epoch:80000/100000] Loss: 0.1063\n",
      "[Epoch:90000/100000] Loss: 0.0964\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100000\n",
    "total = 0\n",
    "correct = 0\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    prediction = model(x)\n",
    "    loss = criterion(prediction, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10000 == 0:\n",
    "        print(f'[Epoch:{epoch}/{epochs}] Loss: {round(loss.item(), 4)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "y = [[[0], [1], [1], [0]]]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        output = self.linear(X)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "model = LogisticRegression(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:0/100000] Loss: 0.7333\n",
      "[Epoch:1000/100000] Loss: 0.7148\n",
      "[Epoch:2000/100000] Loss: 0.7057\n",
      "[Epoch:3000/100000] Loss: 0.7013\n",
      "[Epoch:4000/100000] Loss: 0.6991\n",
      "[Epoch:5000/100000] Loss: 0.6979\n",
      "[Epoch:6000/100000] Loss: 0.6972\n",
      "[Epoch:7000/100000] Loss: 0.6968\n",
      "[Epoch:8000/100000] Loss: 0.6964\n",
      "[Epoch:9000/100000] Loss: 0.6961\n",
      "[Epoch:10000/100000] Loss: 0.6959\n",
      "[Epoch:11000/100000] Loss: 0.6957\n",
      "[Epoch:12000/100000] Loss: 0.6955\n",
      "[Epoch:13000/100000] Loss: 0.6953\n",
      "[Epoch:14000/100000] Loss: 0.6951\n",
      "[Epoch:15000/100000] Loss: 0.695\n",
      "[Epoch:16000/100000] Loss: 0.6948\n",
      "[Epoch:17000/100000] Loss: 0.6947\n",
      "[Epoch:18000/100000] Loss: 0.6946\n",
      "[Epoch:19000/100000] Loss: 0.6945\n",
      "[Epoch:20000/100000] Loss: 0.6944\n",
      "[Epoch:21000/100000] Loss: 0.6943\n",
      "[Epoch:22000/100000] Loss: 0.6942\n",
      "[Epoch:23000/100000] Loss: 0.6941\n",
      "[Epoch:24000/100000] Loss: 0.694\n",
      "[Epoch:25000/100000] Loss: 0.694\n",
      "[Epoch:26000/100000] Loss: 0.6939\n",
      "[Epoch:27000/100000] Loss: 0.6939\n",
      "[Epoch:28000/100000] Loss: 0.6938\n",
      "[Epoch:29000/100000] Loss: 0.6938\n",
      "[Epoch:30000/100000] Loss: 0.6937\n",
      "[Epoch:31000/100000] Loss: 0.6937\n",
      "[Epoch:32000/100000] Loss: 0.6936\n",
      "[Epoch:33000/100000] Loss: 0.6936\n",
      "[Epoch:34000/100000] Loss: 0.6936\n",
      "[Epoch:35000/100000] Loss: 0.6935\n",
      "[Epoch:36000/100000] Loss: 0.6935\n",
      "[Epoch:37000/100000] Loss: 0.6935\n",
      "[Epoch:38000/100000] Loss: 0.6934\n",
      "[Epoch:39000/100000] Loss: 0.6934\n",
      "[Epoch:40000/100000] Loss: 0.6934\n",
      "[Epoch:41000/100000] Loss: 0.6934\n",
      "[Epoch:42000/100000] Loss: 0.6934\n",
      "[Epoch:43000/100000] Loss: 0.6933\n",
      "[Epoch:44000/100000] Loss: 0.6933\n",
      "[Epoch:45000/100000] Loss: 0.6933\n",
      "[Epoch:46000/100000] Loss: 0.6933\n",
      "[Epoch:47000/100000] Loss: 0.6933\n",
      "[Epoch:48000/100000] Loss: 0.6933\n",
      "[Epoch:49000/100000] Loss: 0.6933\n",
      "[Epoch:50000/100000] Loss: 0.6933\n",
      "[Epoch:51000/100000] Loss: 0.6933\n",
      "[Epoch:52000/100000] Loss: 0.6932\n",
      "[Epoch:53000/100000] Loss: 0.6932\n",
      "[Epoch:54000/100000] Loss: 0.6932\n",
      "[Epoch:55000/100000] Loss: 0.6932\n",
      "[Epoch:56000/100000] Loss: 0.6932\n",
      "[Epoch:57000/100000] Loss: 0.6932\n",
      "[Epoch:58000/100000] Loss: 0.6932\n",
      "[Epoch:59000/100000] Loss: 0.6932\n",
      "[Epoch:60000/100000] Loss: 0.6932\n",
      "[Epoch:61000/100000] Loss: 0.6932\n",
      "[Epoch:62000/100000] Loss: 0.6932\n",
      "[Epoch:63000/100000] Loss: 0.6932\n",
      "[Epoch:64000/100000] Loss: 0.6932\n",
      "[Epoch:65000/100000] Loss: 0.6932\n",
      "[Epoch:66000/100000] Loss: 0.6932\n",
      "[Epoch:67000/100000] Loss: 0.6932\n",
      "[Epoch:68000/100000] Loss: 0.6932\n",
      "[Epoch:69000/100000] Loss: 0.6932\n",
      "[Epoch:70000/100000] Loss: 0.6932\n",
      "[Epoch:71000/100000] Loss: 0.6932\n",
      "[Epoch:72000/100000] Loss: 0.6932\n",
      "[Epoch:73000/100000] Loss: 0.6932\n",
      "[Epoch:74000/100000] Loss: 0.6932\n",
      "[Epoch:75000/100000] Loss: 0.6932\n",
      "[Epoch:76000/100000] Loss: 0.6932\n",
      "[Epoch:77000/100000] Loss: 0.6932\n",
      "[Epoch:78000/100000] Loss: 0.6932\n",
      "[Epoch:79000/100000] Loss: 0.6932\n",
      "[Epoch:80000/100000] Loss: 0.6932\n",
      "[Epoch:81000/100000] Loss: 0.6932\n",
      "[Epoch:82000/100000] Loss: 0.6932\n",
      "[Epoch:83000/100000] Loss: 0.6932\n",
      "[Epoch:84000/100000] Loss: 0.6932\n",
      "[Epoch:85000/100000] Loss: 0.6932\n",
      "[Epoch:86000/100000] Loss: 0.6932\n",
      "[Epoch:87000/100000] Loss: 0.6932\n",
      "[Epoch:88000/100000] Loss: 0.6932\n",
      "[Epoch:89000/100000] Loss: 0.6932\n",
      "[Epoch:90000/100000] Loss: 0.6932\n",
      "[Epoch:91000/100000] Loss: 0.6932\n",
      "[Epoch:92000/100000] Loss: 0.6932\n",
      "[Epoch:93000/100000] Loss: 0.6932\n",
      "[Epoch:94000/100000] Loss: 0.6932\n",
      "[Epoch:95000/100000] Loss: 0.6932\n",
      "[Epoch:96000/100000] Loss: 0.6932\n",
      "[Epoch:97000/100000] Loss: 0.6932\n",
      "[Epoch:98000/100000] Loss: 0.6931\n",
      "[Epoch:99000/100000] Loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100000\n",
    "total = 0\n",
    "correct = 0\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    prediction = model(x)\n",
    "    loss = criterion(prediction, y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'[Epoch:{epoch}/{epochs}] Loss: {round(loss.item(), 4)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
